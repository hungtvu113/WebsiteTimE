name: ðŸ“Š Code Quality & Performance

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Cháº¡y hÃ ng ngÃ y lÃºc 2:00 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  NODE_VERSION: '18'
  PNPM_VERSION: '8'

jobs:
  # ðŸ“Š SonarCloud Analysis
  sonarcloud:
    name: ðŸ“Š SonarCloud Analysis
    runs-on: ubuntu-latest
    if: github.event_name != 'schedule' || github.ref == 'refs/heads/main'
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Shallow clones should be disabled for better analysis

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¥ Install dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸ§ª Run tests with coverage
        run: |
          pnpm backend:test --coverage
        env:
          NODE_ENV: test

      - name: ðŸ“Š SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # âš¡ Performance Testing
  performance:
    name: âš¡ Performance Testing
    runs-on: ubuntu-latest
    services:
      mongodb:
        image: mongo:6.0
        env:
          MONGO_INITDB_ROOT_USERNAME: admin
          MONGO_INITDB_ROOT_PASSWORD: password123
          MONGO_INITDB_DATABASE: qltime_test
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand(\"ping\")'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¥ Install dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸš€ Start backend for testing
        run: |
          pnpm backend:build
          pnpm backend:start &
          echo $! > backend.pid
          
          # Wait for backend to start
          for i in {1..30}; do
            if curl -f http://localhost:3001/health > /dev/null 2>&1; then
              echo "âœ… Backend is ready"
              break
            fi
            echo "â³ Waiting for backend... ($i/30)"
            sleep 2
          done
        env:
          MONGODB_URI: mongodb://admin:password123@localhost:27017/qltime_test?authSource=admin
          JWT_SECRET: test_jwt_secret
          NODE_ENV: production
          PORT: 3001

      - name: ðŸ“¦ Install Artillery
        run: npm install -g artillery@latest

      - name: âš¡ Run API performance tests
        run: |
          echo "âš¡ Running API performance tests..."
          
          # Create performance test config if not exists
          if [ ! -f "performance-test.yml" ]; then
            cat > performance-test.yml << EOF
          config:
            target: 'http://localhost:3001'
            phases:
              - duration: 60
                arrivalRate: 10
                name: "Warm up"
              - duration: 120
                arrivalRate: 20
                name: "Load test"
              - duration: 60
                arrivalRate: 50
                name: "Stress test"
            processor: "./performance-processor.js"
          
          scenarios:
            - name: "Health check"
              weight: 20
              flow:
                - get:
                    url: "/health"
            
            - name: "API endpoints"
              weight: 80
              flow:
                - get:
                    url: "/api"
                    expect:
                      - statusCode: 200
          EOF
          fi
          
          # Run performance tests
          artillery run performance-test.yml --output performance-results.json
          
          # Generate HTML report
          artillery report performance-results.json --output performance-report.html

      - name: ðŸ“Š Analyze performance results
        run: |
          echo "ðŸ“Š Analyzing performance results..."
          
          # Extract key metrics
          if [ -f "performance-results.json" ]; then
            echo "ðŸ“ˆ Performance Summary:"
            echo "- Total requests: $(jq '.aggregate.counters["http.requests"] // 0' performance-results.json)"
            echo "- Success rate: $(jq '.aggregate.counters["http.responses"] // 0' performance-results.json)"
            echo "- Average response time: $(jq '.aggregate.latency.mean // 0' performance-results.json)ms"
            echo "- 95th percentile: $(jq '.aggregate.latency.p95 // 0' performance-results.json)ms"
            echo "- 99th percentile: $(jq '.aggregate.latency.p99 // 0' performance-results.json)ms"
            
            # Check if performance is acceptable
            AVG_RESPONSE=$(jq '.aggregate.latency.mean // 0' performance-results.json)
            P95_RESPONSE=$(jq '.aggregate.latency.p95 // 0' performance-results.json)
            
            if (( $(echo "$AVG_RESPONSE > 1000" | bc -l) )); then
              echo "âš ï¸ Average response time is high: ${AVG_RESPONSE}ms"
            fi
            
            if (( $(echo "$P95_RESPONSE > 2000" | bc -l) )); then
              echo "âš ï¸ 95th percentile response time is high: ${P95_RESPONSE}ms"
            fi
          fi

      - name: ðŸ›‘ Stop backend
        if: always()
        run: |
          if [ -f backend.pid ]; then
            kill $(cat backend.pid) || true
            rm backend.pid
          fi

      - name: ðŸ“¦ Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: |
            performance-results.json
            performance-report.html
          retention-days: 30

  # ðŸŒ Frontend Lighthouse Audit
  lighthouse:
    name: ðŸŒ Lighthouse Audit
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¥ Install dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸ—ï¸ Build frontend
        run: pnpm frontend:build
        env:
          NEXT_PUBLIC_API_URL: http://localhost:3001

      - name: ðŸš€ Start frontend
        run: |
          pnpm frontend:start &
          echo $! > frontend.pid
          
          # Wait for frontend to start
          for i in {1..30}; do
            if curl -f http://localhost:3000 > /dev/null 2>&1; then
              echo "âœ… Frontend is ready"
              break
            fi
            echo "â³ Waiting for frontend... ($i/30)"
            sleep 2
          done

      - name: ðŸŒ Run Lighthouse CI
        run: |
          npm install -g @lhci/cli@latest
          
          # Create Lighthouse CI config if not exists
          if [ ! -f ".lighthouserc.json" ]; then
            cat > .lighthouserc.json << EOF
          {
            "ci": {
              "collect": {
                "url": ["http://localhost:3000"],
                "numberOfRuns": 3
              },
              "assert": {
                "assertions": {
                  "categories:performance": ["warn", {"minScore": 0.8}],
                  "categories:accessibility": ["error", {"minScore": 0.9}],
                  "categories:best-practices": ["warn", {"minScore": 0.8}],
                  "categories:seo": ["warn", {"minScore": 0.8}]
                }
              },
              "upload": {
                "target": "temporary-public-storage"
              }
            }
          }
          EOF
          fi
          
          lhci autorun

      - name: ðŸ›‘ Stop frontend
        if: always()
        run: |
          if [ -f frontend.pid ]; then
            kill $(cat frontend.pid) || true
            rm frontend.pid
          fi

  # ðŸ”’ Security Analysis
  security:
    name: ðŸ”’ Security Analysis
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ” Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: javascript

      - name: ðŸ” Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

      - name: ðŸ”’ Run Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/secrets
            p/javascript
            p/typescript
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

  # ðŸ“š Documentation Check
  docs:
    name: ðŸ“š Documentation Check
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“š Check README files
        run: |
          echo "ðŸ“š Checking documentation..."
          
          # Check if main README exists and is not empty
          if [ ! -f "README.md" ] || [ ! -s "README.md" ]; then
            echo "âŒ Main README.md is missing or empty"
            exit 1
          fi
          
          # Check for other important docs
          DOCS_TO_CHECK=("frontend/README.md" "backend/README.md")
          
          for doc in "${DOCS_TO_CHECK[@]}"; do
            if [ ! -f "$doc" ]; then
              echo "âš ï¸ Missing documentation: $doc"
            else
              echo "âœ… Found: $doc"
            fi
          done

      - name: ðŸ“ Check for TODO comments
        run: |
          echo "ðŸ“ Checking for TODO comments..."
          
          TODO_COUNT=$(grep -r "TODO\|FIXME\|HACK" --include="*.ts" --include="*.tsx" --include="*.js" --include="*.jsx" . | wc -l)
          
          echo "ðŸ“ Found $TODO_COUNT TODO/FIXME/HACK comments"
          
          if [ "$TODO_COUNT" -gt 50 ]; then
            echo "âš ï¸ High number of TODO comments found. Consider addressing some of them."
          fi

      - name: ðŸ“Š Generate documentation report
        run: |
          echo "ðŸ“Š Generating documentation report..."
          
          cat > docs-report.md << EOF
          # ðŸ“š Documentation Report
          
          Generated on: $(date)
          
          ## ðŸ“‹ Documentation Status
          - Main README: $([ -f "README.md" ] && echo "âœ… Present" || echo "âŒ Missing")
          - Frontend README: $([ -f "frontend/README.md" ] && echo "âœ… Present" || echo "âŒ Missing")
          - Backend README: $([ -f "backend/README.md" ] && echo "âœ… Present" || echo "âŒ Missing")
          - Docker README: $([ -f "README-DOCKER.md" ] && echo "âœ… Present" || echo "âŒ Missing")
          
          ## ðŸ“ Code Comments
          - TODO comments: $(grep -r "TODO" --include="*.ts" --include="*.tsx" --include="*.js" --include="*.jsx" . | wc -l)
          - FIXME comments: $(grep -r "FIXME" --include="*.ts" --include="*.tsx" --include="*.js" --include="*.jsx" . | wc -l)
          - HACK comments: $(grep -r "HACK" --include="*.ts" --include="*.tsx" --include="*.js" --include="*.jsx" . | wc -l)
          EOF

      - name: ðŸ“¦ Upload documentation report
        uses: actions/upload-artifact@v4
        with:
          name: documentation-report
          path: docs-report.md
          retention-days: 30
